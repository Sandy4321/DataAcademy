Project Proposal.

Using the San Francisco Crime Data prediction on Kaggle. Convert to this data into graph structure by applying techniques like graph analytics , spectral embedding and manifold learning. Converting this large data set into a graph structure will enhance the extraction of meaningful insights from the data. We can see who is connected to who in
terms of committing crime, we can also detect who is the neighbor to who, who is the most important node in the network.etc

The spectral embedding aspect will enable us to lower the dimension of the large data set and still maintaining the underlying structure of the network. This will help us visualize the network in various forms. Manifold learning is then applied to the spectral embedding approach together with Isometric mapping( also known as Laplacian Eigen Maps).

In essence , we seek in this proposal to apply graph analytics in big data, since machine learning is a sequence of data manipulations and graph analytics is one of those sequences. It will be very interesting to see businesses representing their big data as network structures. The source of the data is kaggle website - San Francisco Crime Data Prediction.

I will leave the graph analytics part when I find myself at the Data Incubator Academy, but will explore this data set using the tradition approach of applying data science techniques by drawing the map of San Francisco which will enable one to visualize the various places where crimes do occur most often. I will also explore the type of crimes that do often most of the time , visualize the crimes category using heat-maps and bar plots.

As it can be seen from the Summary, algorithms alone are not sufficient to make predictions given a data set , so we seek to apply feature engineering so as to extract all the necessary and important features from the data as possible and throwing out irrelevant features, this could be done with expertise.